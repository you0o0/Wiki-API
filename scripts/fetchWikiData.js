import fs from "fs";
import path from "path";
import fetch from "node-fetch";

const BASE_DIR = "./data/wikipedia";
const CATEGORIES = {
  Ø¹Ù„ÙˆÙ…: "Science",
  ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§: "Technology",
  Ø«Ù‚Ø§ÙØ©: "Culture",
  ØªØ§Ø±ÙŠØ®: "History",
  Ø¬ØºØ±Ø§ÙÙŠØ§: "Geography",
  Ø±ÙŠØ§Ø¶Ø©: "Sports",
  Ø·Ø¨: "Medicine",
  "ØµØ­Ø© Ù†ÙØ³ÙŠØ©": "MentalHealth",
  Ø¨ÙŠØ¦Ø©: "Environment",
  ØªØºØ°ÙŠØ©: "Nutrition",
  Ø³ÙŠØ§Ø­Ø©: "Tourism",
};

async function fetchCategoryMembers(category) {
  const url = `https://ar.wikipedia.org/w/api.php?action=query&format=json&origin=*&list=categorymembers&cmtitle=ØªØµÙ†ÙŠÙ:${category}&cmlimit=max`;
  const res = await fetch(url);
  const data = await res.json();
  return data.query?.categorymembers || [];
}

async function fetchArticleHTML(title) {
  try {
    const encoded = encodeURIComponent(title);
    const url = `https://ar.wikipedia.org/api/rest_v1/page/html/${encoded}`;
    const res = await fetch(url);
    if (!res.ok) return null;
    const html = await res.text();
    return html;
  } catch (e) {
    console.error("âŒ HTML Fetch Error:", title, e.message);
    return null;
  }
}

async function fetchArticleMeta(title) {
  const encoded = encodeURIComponent(title);
  const url = `https://ar.wikipedia.org/w/api.php?action=query&prop=pageimages|info|description&format=json&inprop=url&origin=*&titles=${encoded}&pithumbsize=400`;
  const res = await fetch(url);
  const data = await res.json();
  const page = Object.values(data.query.pages)[0];
  return {
    title: page.title,
    description: page.description || "",
    image: page.thumbnail?.source || "",
    lastrevid: page.lastrevid || "",
    url: page.fullurl || "",
  };
}

async function processCategory(arName, enFile) {
  console.log(`\n--- Processing category: ${arName} -> ${enFile}.json`);
  const members = await fetchCategoryMembers(arName);
  const validMembers = members.filter(m => !m.title.startsWith("Ù…Ø³ØªØ®Ø¯Ù…:") && !m.title.startsWith("User:"));
  console.log(`  members: ${validMembers.length}`);

  const results = [];
  for (const member of validMembers) {
    const meta = await fetchArticleMeta(member.title);
    const html = await fetchArticleHTML(member.title);
    if (!html) continue;

    results.push({
      title: meta.title,
      description: meta.description,
      image: meta.image,
      url: meta.url,
      lastrevid: meta.lastrevid,
      html: html, // âœ… Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¨ØµÙŠØºØ© HTML Ø§Ù„Ø¬Ø§Ù‡Ø²Ø©
    });
  }

  const outputDir = path.join(BASE_DIR, "categories");
  fs.mkdirSync(outputDir, { recursive: true });
  const filePath = path.join(outputDir, `${enFile}.json`);
  fs.writeFileSync(filePath, JSON.stringify(results, null, 2), "utf-8");
  console.log(`  âœ… saved: ${filePath}`);
}

async function fetchFeaturedArticle() {
  console.log(`\n--- Fetching Featured Article`);
  const url = `https://ar.wikipedia.org/api/rest_v1/feed/featured/2025/10/18`;
  const res = await fetch(url);
  const data = await res.json();
  const article = data.tfa; // ÙÙ‚Ø· Ø§Ù„Ù…Ù‚Ø§Ù„Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©
  if (!article) return;

  const featured = {
    title: article.titles?.normalized,
    description: article.description,
    image: article.thumbnail?.source || "",
    url: article.content_urls?.desktop?.page,
    html: await fetchArticleHTML(article.titles?.normalized),
  };

  const outputDir = path.join(BASE_DIR, "featured");
  fs.mkdirSync(outputDir, { recursive: true });
  const filePath = path.join(outputDir, "featured.json");
  fs.writeFileSync(filePath, JSON.stringify(featured, null, 2), "utf-8");
  console.log(`  âœ… featured saved: ${filePath}`);
}

(async () => {
  console.log("ðŸš€ Start fetching Wikipedia data (HTML mode)...");
  for (const [ar, en] of Object.entries(CATEGORIES)) {
    await processCategory(ar, en);
  }
  await fetchFeaturedArticle();
  console.log("ðŸŽ‰ All done with HTML articles!");
})();
